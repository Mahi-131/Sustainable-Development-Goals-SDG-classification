{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "colab": {
      "name": "MDSC_302_Assignment_20227.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01f07c4b"
      },
      "source": [
        "## Importing necessary libraries"
      ],
      "id": "01f07c4b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d9ecef4"
      },
      "source": [
        "# standard library\n",
        "from typing import List\n",
        "\n",
        "# data wrangling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# visualisation\n",
        "import plotly.express as px\n",
        "import plotly.io as pio\n",
        "\n",
        "# nlp\n",
        "import spacy\n",
        "\n",
        "# data modelling\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, f1_score\n",
        "\n",
        "# utils\n",
        "from tqdm import tqdm\n",
        "\n",
        "# local packages\n",
        "from helpers import plot_confusion_matrix, get_top_features, fix_sdg_name\n",
        "\n",
        "print('Loaded!')"
      ],
      "id": "3d9ecef4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEuOqw-rQBln"
      },
      "source": [
        ""
      ],
      "id": "vEuOqw-rQBln"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q24-ttVPso3"
      },
      "source": [
        "#### Here we are using Spacy for removing unnecessary words such as stopping words which doesn't provide any meaning and disabling ner(named entity recognition)."
      ],
      "id": "7q24-ttVPso3"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b918fd4"
      },
      "source": [
        "# other settings\n",
        "pio.templates.default = 'plotly_dark'\n",
        "spacy.prefer_gpu()\n",
        "nlp = spacy.load('en_core_web_sm', disable = ['ner'])\n"
      ],
      "id": "7b918fd4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb58b62e"
      },
      "source": [
        "## Loading data and exploring"
      ],
      "id": "eb58b62e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04f7ba09"
      },
      "source": [
        "dataset = pd.read_csv('https://zenodo.org/record/5550238/files/osdg-community-dataset-v21-09-30.csv?download=1')\n",
        "print('Shape:', dataset.shape)\n",
        "#display(dataset['text'].values)\n",
        "#display(dataset.head())"
      ],
      "id": "04f7ba09",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18d5b11e"
      },
      "source": [
        "# calculating cumulative probability over agreement scores\n",
        "df_lambda = dataset['agreement'].value_counts(normalize = True).sort_index().cumsum().to_frame(name = 'p_sum')\n",
        "df_lambda.reset_index(inplace = True)\n",
        "df_lambda.rename({'index': 'agreement'}, axis = 1, inplace = True)\n",
        "\n",
        "print('Shape:', df_lambda.shape)\n"
      ],
      "id": "18d5b11e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10c2a1e0"
      },
      "source": [
        "# keeping only the texts whose suggested sdg labels is accepted and the agreement score is at least .6\n",
        "print('Shape before:', dataset.shape)\n",
        "dataset = dataset.query('agreement >= .6 and labels_positive > labels_negative').copy()\n",
        "print('Shape after :', dataset.shape)\n"
      ],
      "id": "10c2a1e0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yplxlLvvWP9H"
      },
      "source": [
        "df3 = dataset['sdg'].value_counts()\n",
        "df3.columns = ['sdg', 'count']\n",
        "print (df3.sort_index())"
      ],
      "id": "yplxlLvvWP9H",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c171754"
      },
      "source": [
        "df_lambda = dataset.groupby('sdg', as_index = False).agg(count = ('text_id', 'count'))\n",
        "df_lambda['share'] = df_lambda['count'].divide(df_lambda['count'].sum()).multiply(100)\n",
        "print('Shape:', df_lambda.shape)\n",
        "display(df_lambda.head())"
      ],
      "id": "3c171754",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6g_2Jj3kdc7Y"
      },
      "source": [
        "## Preprocess_spacy function which takes text from the dataframe and returns meaningful words"
      ],
      "id": "6g_2Jj3kdc7Y"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "086f46d1"
      },
      "source": [
        "def preprocess_spacy(alpha: List[str]) -> List[str]:\n",
        "   \n",
        "    docs = list()\n",
        "    \n",
        "    for doc in tqdm(nlp.pipe(alpha, batch_size = 128)):\n",
        "        tokens = list()\n",
        "        for token in doc:\n",
        "            if token.pos_ in ['NOUN', 'VERB', 'ADJ']:\n",
        "                tokens.append(token.lemma_)\n",
        "        docs.append(' '.join(tokens))\n",
        "    \n",
        "    return docs\n",
        "  "
      ],
      "id": "086f46d1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR9psM7AqJQM"
      },
      "source": [
        "### Calling the preprocess_spacy function "
      ],
      "id": "IR9psM7AqJQM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "9f83bfc9"
      },
      "source": [
        "dataset['docs'] = preprocess_spacy(dataset['text'].values)\n",
        "print('\\nShape:', dataset.shape)\n",
        "display(dataset.head())"
      ],
      "id": "9f83bfc9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaAYpHv1h8au"
      },
      "source": [
        "## Splitting the dataset into training and testing data."
      ],
      "id": "BaAYpHv1h8au"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "515f3489"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    dataset['docs'].values, \n",
        "    dataset['sdg'].values, \n",
        "    test_size = .3,\n",
        "    random_state = 42\n",
        ")"
      ],
      "id": "515f3489",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CWS0v8cYhsk"
      },
      "source": [
        "## Multi Classification starts here ! ! ! !\n",
        "### I am using ExtraTreesClassifier for multi-classification\n"
      ],
      "id": "6CWS0v8cYhsk"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ecc1e0f"
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "pipe = Pipeline([\n",
        "    ('vectoriser', TfidfVectorizer(\n",
        "        ngram_range = (1, 2),\n",
        "        max_df = 0.75,\n",
        "        min_df = 2,\n",
        "        max_features = 100_000\n",
        "    )),\n",
        "    ('selector', SelectKBest(f_classif, k = 5_000)),\n",
        "    ('clf',ExtraTreesClassifier())\n",
        "])\n",
        "\n",
        "pipe.fit(X_train, y_train)"
      ],
      "id": "8ecc1e0f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIajvJeDYUPg"
      },
      "source": [
        "## Getting Model Accuracy"
      ],
      "id": "cIajvJeDYUPg"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c717752f"
      },
      "source": [
        "y_hat = pipe.predict(X_test)\n",
        "from sklearn.metrics import accuracy_score\n",
        "model_accuracy = accuracy_score(y_test, y_hat)\n",
        "print('Accuracy of the Model = ', int(model_accuracy*100),'%')"
      ],
      "id": "c717752f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRLekb36YPa0"
      },
      "source": [
        "## Confusion Matrix"
      ],
      "id": "oRLekb36YPa0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr7nz-vRYOiR"
      },
      "source": [
        "plot_confusion_matrix(y_test, y_hat)"
      ],
      "id": "dr7nz-vRYOiR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7NpIb8xZxp4"
      },
      "source": [
        "## Predicting the goal and respective probabilities for training dataset."
      ],
      "id": "d7NpIb8xZxp4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7aMmTXOvBdt"
      },
      "source": [
        "# Here I took 3rd text in the text column of dataset and predicted the SDG goal number.\n",
        "predicted_goal= pipe.predict([X_test[3]])\n",
        "print(predicted_goal)"
      ],
      "id": "H7aMmTXOvBdt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mY38uebSsn6z"
      },
      "source": [
        "# Predicting the probability of each and every goal.\n",
        "predicted_probabilities = pipe.predict_proba([X_test[3]])\n",
        "print(predicted_probabilities)"
      ],
      "id": "mY38uebSsn6z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VV-9bE45aGuP"
      },
      "source": [
        "### Classification report of the model"
      ],
      "id": "VV-9bE45aGuP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmOLzjYGoMcO"
      },
      "source": [
        "print(classification_report(y_test, y_hat, zero_division = 0))"
      ],
      "id": "GmOLzjYGoMcO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfacuR0EsKlD"
      },
      "source": [
        "!pip install pdfminer"
      ],
      "id": "hfacuR0EsKlD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXaLVoqaWnVk"
      },
      "source": [
        "## Uploading PDF and converting to text "
      ],
      "id": "CXaLVoqaWnVk"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QO-W00JfBN8O"
      },
      "source": [
        "!pip install pdfminer"
      ],
      "id": "QO-W00JfBN8O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ar06yPcEbDt"
      },
      "source": [
        "#Importing required libraries\n",
        "\n",
        "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
        "from pdfminer.converter import TextConverter\n",
        "from pdfminer.layout import LAParams\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "from io import StringIO\n",
        "import nltk\n",
        "import os\n",
        "import re\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "\n",
        "# convert_pdf_to_text is the function which takes pdf file and converts it into text and returns text.\n",
        "\n",
        "def convert_pdf_to_txt(path):\n",
        "    rsrcmgr = PDFResourceManager()\n",
        "    retstr = StringIO()\n",
        "    codec = 'utf-8'\n",
        "    laparams = LAParams()\n",
        "    device = TextConverter(rsrcmgr, retstr, laparams=laparams)\n",
        "    fp = open(path, 'rb')\n",
        "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
        "    password = \"\"\n",
        "    maxpages = 0\n",
        "    caching = True\n",
        "    pagenos = set()\n",
        "\n",
        "    for page in PDFPage.get_pages(fp, pagenos, maxpages=maxpages, password=password, caching=caching, check_extractable=True):\n",
        "        interpreter.process_page(page)\n",
        "\n",
        "    text = retstr.getvalue()\n",
        "\n",
        "    fp.close()\n",
        "    device.close()\n",
        "    retstr.close()\n",
        "    return text\n"
      ],
      "id": "0ar06yPcEbDt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF5EhgqLamZ7"
      },
      "source": [
        "## Uploading PDF to google colab"
      ],
      "id": "AF5EhgqLamZ7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7T94wDkMz3y"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "id": "j7T94wDkMz3y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZE4yOKOxNUF-"
      },
      "source": [
        "# Getting the uploaded file name \n",
        "var = (*uploaded,)\n",
        "str2= var[0]\n",
        "str2"
      ],
      "id": "ZE4yOKOxNUF-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "447YcjDiVs9m"
      },
      "source": [
        "# Creating path of the uploaded file\n",
        "str1 = \"/content/\"\n",
        "Final_path = str1+str2\n",
        "Final_path"
      ],
      "id": "447YcjDiVs9m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPdQdZLFMx-o"
      },
      "source": [
        "#Giving final path to the text\n",
        "text = convert_pdf_to_txt(Final_path)\n"
      ],
      "id": "tPdQdZLFMx-o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_vXZHGc4m-7"
      },
      "source": [
        "# Creating a new dataframe for giving text to preprocessspacy function.\n",
        "# Because it take the values of the column as input.\n",
        "# So created a dataframe and inserting txt into particular column called \"docs\" in the dataframe\n",
        "\n",
        "Final_df  = pd.DataFrame()\n",
        "Final_df['text'] = [text]"
      ],
      "id": "D_vXZHGc4m-7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcA3JqRj4rmM"
      },
      "source": [
        "# Giving the text which is in the dataframe to preprocess_spacy function\n",
        "\n",
        "Final_df['docs'] = preprocess_spacy(Final_df['text'].values)"
      ],
      "id": "kcA3JqRj4rmM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X65YN3E7diqP"
      },
      "source": [
        "#Predicting the Final goal of a pdf\n",
        "\n",
        "Final_predicted_goal = pipe.predict(Final_df['docs'])\n",
        "print(\"SDG Goal : \",Final_predicted_goal)"
      ],
      "id": "X65YN3E7diqP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFhHbovN_LoG"
      },
      "source": [
        "# Predicting the probabilities of every goal according to uploaded pdf.\n",
        "\n",
        "Final_predicted_probabilities = pipe.predict_proba(Final_df['docs']).flatten()\n",
        "print(\"Probabilities of each goal in order :\",Final_predicted_probabilities)"
      ],
      "id": "QFhHbovN_LoG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHQt3fXJekUW"
      },
      "source": [
        "## Printing a final dataframe with \"Goal_Numbers\" and \"Goal_Probabilities\"!!!!"
      ],
      "id": "GHQt3fXJekUW"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDTmiNPMGfM8"
      },
      "source": [
        "goals_data= {'SDG Goals':['No Poverty', 'Zero Hunger', 'Good Health and Well-Being',\n",
        "                             'Quality Education', 'Gender Equality', 'Clean Water And Sanitation', \n",
        "                             'Affordable Clean Energy','Decent Work And Economic Growth',\n",
        "                             'Industry,Innovation And Infrastructure', 'Reduced Inqualities',\n",
        "                             'Sustainable Cities And Communities', 'Responsible Consumption And Production',\n",
        "                             'Climate Action', 'Life Below Earth', 'Life on Land'],\n",
        "             'Goal_Number':[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]}\n",
        "df1  = pd.DataFrame(goals_data)\n",
        "Prob= pipe.predict_proba(Final_df['docs']).flatten() # Probabilities of each goals\n",
        "df1['Probability_Scores']= Prob\n",
        "Final_Table = df1.sort_values([\"Probability_Scores\"], ascending=False) # Sorting the goals based on highest probabilities\n",
        "print(Final_Table) #Printing the final table"
      ],
      "id": "MDTmiNPMGfM8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyUStRqCfKEA"
      },
      "source": [
        ""
      ],
      "id": "iyUStRqCfKEA",
      "execution_count": null,
      "outputs": []
    }
  ]
}